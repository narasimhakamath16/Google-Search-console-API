{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68795ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required python packages\n",
    "!pip install oauth2client\n",
    "!pip install google-api-python-client\n",
    "!pip install httplib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd6d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from oauth2client.client import OAuth2WebServerFlow\n",
    "from googleapiclient.discovery import build\n",
    "import httplib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09756456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Your Google Cloud Project Client ID & Client Secrets\n",
    "CLIENT_ID = \"Your client ID\"\n",
    "CLIENT_SECRET = \"Your client secret\"\n",
    "\n",
    "# Define Oath scopes with read only access\n",
    "OAUTH_SCOPE = \"https://www.googleapis.com/auth/webmasters.readonly\"\n",
    "\n",
    "#OAUTH_SCOPE = \"https://www.googleapis.com/auth/webmasters\"\n",
    "\n",
    "# Redirect URI to open Authorization Code Window in Browser\n",
    "REDIRECT_URI = 'Redirect URI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa37e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build URL that generates Authorization Code\n",
    "flow = OAuth2WebServerFlow(CLIENT_ID, CLIENT_SECRET, OAUTH_SCOPE, REDIRECT_URI)\n",
    "authorize_url = flow.step1_get_authorize_url()\n",
    "\n",
    "#Print Authorization URL\n",
    "print(\"Go to the following link in your browser: \" + authorize_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2605f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auth_code = input(\"Enter your Authorization Code here:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58db90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get credentials to build GSC API service\n",
    "credentials = flow.step2_exchange(auth_code)\n",
    "print(\"The credentials are generated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an httplib2.Http object and authorize it with our credentials\n",
    "http = httplib2.Http()\n",
    "\n",
    "#authorize credentials\n",
    "creds = credentials.authorize(http)\n",
    "\n",
    "#building a service to access various features of GSC API\n",
    "webmasters_service = build('searchconsole', 'v1', http=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7321159a",
   "metadata": {},
   "source": [
    "    List of sites for my google account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee793b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "site_list = webmasters_service.sites().list().execute()\n",
    "\n",
    "print(site_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6367d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Using a list comprehension to extract site URLs\n",
    "site_urls = [entry['siteUrl'] for entry in site_list['siteEntry']]\n",
    "\n",
    "# Print the list of site URLs\n",
    "print(site_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the site URLs\n",
    "df = pd.DataFrame({'Site URLs': site_urls})\n",
    "\n",
    "# Define the Excel file name\n",
    "excel_file = 'site_urls.xlsx'\n",
    "\n",
    "# Export the DataFrame to an Excel file\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(f\"Site URLs have been saved to '{excel_file}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4562dce",
   "metadata": {},
   "source": [
    "    Search analytics data with row limit of 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b46ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the website we want to get the data for\n",
    "website = \"https://www.knorr.com/uk/\"\n",
    "\n",
    "# build a request body\n",
    "request_body = {\n",
    "    \"startDate\"\t: '2023-01-01',\n",
    "    \"endDate\" : '2023-02-28',\n",
    "    \"dimensions\" : ['QUERY', 'PAGE'],\n",
    "    \"rowLimit\" : 25000,\n",
    "    \"dataState\" : \"final\"\n",
    "}\n",
    "\n",
    "# get the response using request body\n",
    "response_data = webmasters_service.searchanalytics().query(siteUrl=website, body=request_body).execute()\n",
    "print(response_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response_data['rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e018838",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in response_data['rows']:\n",
    "  print(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721257eb",
   "metadata": {},
   "source": [
    "Modified script to append to existing data - Knorr UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bcaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the website we want to get the data for\n",
    "website = \"https://www.knorr.com/uk/\"\n",
    "\n",
    "# create an empty list to store the rows from response\n",
    "all_responses = []\n",
    "\n",
    "# define a startRow\n",
    "startRow = 0\n",
    "\n",
    "while (startRow == 0) or (startRow%25000 == 0):\n",
    "  # build a request body\n",
    "  request_body = {\n",
    "      \"startDate\"\t: '2023-01-01',\n",
    "      \"endDate\" : '2023-01-02',\n",
    "      \"dimensions\" : ['DATE','QUERY', 'PAGE'],\n",
    "      \"rowLimit\" : 25000,\n",
    "      \"dataState\" : \"final\",\n",
    "      'startRow' : startRow\n",
    "      }\n",
    "\n",
    "  #get gsc response\n",
    "  response_data = webmasters_service.searchanalytics().query(siteUrl=website, body=request_body).execute()\n",
    "\n",
    "  #update the rows\n",
    "  startRow = startRow + len(response_data['rows'])\n",
    "  print(\"fetched up to \" + str(startRow) + \" rows of data\")\n",
    "\n",
    "  # for loop tos save all the rows in all_responses\n",
    "  for row in response_data['rows']:\n",
    "    all_responses.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab733b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a47f84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2e57df",
   "metadata": {},
   "source": [
    "    Build a Dataframe using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c72befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e353369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty list to build a dataframe\n",
    "data_for_df = []\n",
    "\n",
    "for each in all_responses:\n",
    "\n",
    "  temp = []\n",
    "\n",
    "  #date\n",
    "  temp.append(each['keys'][0])\n",
    "\n",
    "  #query\n",
    "  temp.append(each['keys'][1])\n",
    "\n",
    "  #page\n",
    "  temp.append(each['keys'][2])\n",
    "\n",
    "  #clicks\n",
    "  temp.append(each['clicks'])\n",
    "\n",
    "  #impressions\n",
    "  temp.append(each['impressions'])\n",
    "\n",
    "  #ctr\n",
    "  temp.append(each['ctr'])\n",
    "\n",
    "  #position\n",
    "  temp.append(each['position'])\n",
    "\n",
    "  data_for_df.append(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376df923",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daef7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_for_df, columns=['date', 'query', 'page', 'clicks', 'impressions', 'ctr', 'position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dda74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0054632",
   "metadata": {},
   "source": [
    "    Export to CSV or Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b18ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('GSC data 2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814b2bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('GSC data 2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c12a9",
   "metadata": {},
   "source": [
    "    Site by site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the website we want to get the data for\n",
    "website = \"https://www.hellmanns.com/us/es/\"\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"C:/Users/narkamat/GSC_data_4.csv\"\n",
    "\n",
    "# create an empty list to store the rows from response\n",
    "all_responses = []\n",
    "\n",
    "# define a startRow\n",
    "startRow = 0\n",
    "\n",
    "while (startRow == 0) or (startRow%25000 == 0):\n",
    "  # build a request body\n",
    "  request_body = {\n",
    "      \"startDate\"\t: '2023-08-01',\n",
    "      \"endDate\" : '2023-10-31',\n",
    "      \"dimensions\" : ['DATE', 'QUERY', 'PAGE'],\n",
    "      \"rowLimit\" : 25000,\n",
    "      \"dataState\" : \"final\",\n",
    "      'startRow' : startRow\n",
    "      }\n",
    "\n",
    "  #get gsc response\n",
    "  response_data = webmasters_service.searchanalytics().query(siteUrl=website, body=request_body).execute()\n",
    "\n",
    "  #update the rows\n",
    "  startRow = startRow + len(response_data['rows'])\n",
    "  print(\"fetched up to \" + str(startRow) + \" rows of data\")\n",
    "\n",
    "  # for loop tos save all the rows in all_responses\n",
    "  for row in response_data['rows']:\n",
    "    all_responses.append(row)\n",
    "    \n",
    "    \n",
    "#empty list to build a dataframe\n",
    "data_for_df = []\n",
    "\n",
    "for each in all_responses:\n",
    "\n",
    "  temp = []\n",
    "\n",
    "  #date\n",
    "  temp.append(each['keys'][0])\n",
    "\n",
    "  #query\n",
    "  temp.append(each['keys'][1])\n",
    "\n",
    "  #page\n",
    "  temp.append(each['keys'][2])\n",
    "\n",
    "  #clicks\n",
    "  temp.append(each['clicks'])\n",
    "\n",
    "  #impressions\n",
    "  temp.append(each['impressions'])\n",
    "\n",
    "  #ctr\n",
    "  temp.append(each['ctr'])\n",
    "\n",
    "  #position\n",
    "  temp.append(each['position'])\n",
    "\n",
    "  data_for_df.append(temp)\n",
    "\n",
    "# Load the existing CSV file into a DataFrame if it exists, or create a new one\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame(columns=['date', 'query', 'page', 'clicks', 'impressions', 'ctr', 'position'])\n",
    "\n",
    "# Create a new DataFrame for the current website's data\n",
    "new_df = pd.DataFrame(data_for_df, columns=['date', 'query', 'page', 'clicks', 'impressions', 'ctr', 'position'])\n",
    "\n",
    "# Append the new data to the existing DataFrame\n",
    "df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f'Data from {website} appended to {csv_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dabbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
